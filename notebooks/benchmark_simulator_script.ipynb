{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from corner import corner\n",
    "from omegaconf import OmegaConf as OC\n",
    "\n",
    "from sourcerer.fit_surrogate import (\n",
    "    create_train_val_dataloaders,\n",
    "    fit_conditional_normalizing_flow,\n",
    ")\n",
    "from sourcerer.likelihood_estimator import train_lml_source\n",
    "from sourcerer.real_nvp import (\n",
    "    RealNVPs,\n",
    "    Sampler,\n",
    "    TemperedUniform,\n",
    "    kozachenko_leonenko_estimator,\n",
    ")\n",
    "from sourcerer.sbi_classifier_two_sample_test import c2st_scores\n",
    "from sourcerer.simulators import (\n",
    "    GaussianMixtureSimulator,\n",
    "    InverseKinematicsSimulator,\n",
    "    LotkaVolterraSimulator,\n",
    "    SIRSimulator,\n",
    "    SLCPSimulator,\n",
    "    TwoMoonsSimulator,\n",
    ")\n",
    "from sourcerer.sliced_wasserstein import sliced_wasserstein_distance\n",
    "from sourcerer.utils import (\n",
    "    save_cfg_as_yaml,\n",
    "    save_fig,\n",
    "    save_numpy_csv,\n",
    "    save_state_dict,\n",
    "    script_or_command_line_cfg,\n",
    "    set_seed,\n",
    ")\n",
    "from sourcerer.wasserstein_estimator import train_source\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_simulator(cfg):\n",
    "    if cfg.simulator.self == \"two_moons\":\n",
    "        return TwoMoonsSimulator()\n",
    "    elif cfg.simulator.self == \"inverse_kinematics\":\n",
    "        return InverseKinematicsSimulator()\n",
    "    elif cfg.simulator.self == \"slcp\":\n",
    "        return SLCPSimulator()\n",
    "    elif cfg.simulator.self == \"gaussian_mixture\":\n",
    "        return GaussianMixtureSimulator()\n",
    "    elif cfg.simulator.self == \"sir\":\n",
    "        return SIRSimulator()\n",
    "    elif cfg.simulator.self == \"lotka_volterra\":\n",
    "        return LotkaVolterraSimulator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define config\n",
    "# NOTE: These overrides only take effect if this script is run interactively\n",
    "local_overrides = [\n",
    "    \"base.tag=debug\",\n",
    "    \"base.folder=misc\",\n",
    "    \"simulator=inverse_kinematics\",\n",
    "]\n",
    "\n",
    "cfg = script_or_command_line_cfg(\n",
    "    config_name=\"config\",\n",
    "    config_path=\"../conf\",\n",
    "    local_overrides=local_overrides,\n",
    "    name=__name__,\n",
    ")\n",
    "\n",
    "assert cfg.base.tag is not None\n",
    "assert cfg.base.folder is not None\n",
    "\n",
    "print(OC.to_yaml(cfg))\n",
    "\n",
    "save_cfg_as_yaml(\n",
    "    cfg,\n",
    "    f\"{cfg.base.tag}_cfg.yaml\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "if cfg.base.seed is None:\n",
    "    random_random_seed = np.random.randint(2**16)\n",
    "    set_seed(random_random_seed)\n",
    "    save_numpy_csv(\n",
    "        np.array([random_random_seed], dtype=int),\n",
    "        file_name=f\"{cfg.base.tag}_seed.csv\",\n",
    "        folder=cfg.base.folder,\n",
    "        base_path=cfg.base.base_path,\n",
    "    )\n",
    "else:\n",
    "    set_seed(cfg.base.seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Simulator and reference domain. Train a surrogate/load an existing surrogate if necessary.\n",
    "simulator = get_simulator(cfg)\n",
    "simulator = simulator.to(device)\n",
    "\n",
    "box_domain = TemperedUniform(\n",
    "    cfg.simulator.box_domain_lower,\n",
    "    cfg.simulator.box_domain_upper,\n",
    "    simulator.xdim,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = RealNVPs(\n",
    "    flow_length=cfg.surrogate.flow_length,\n",
    "    data_dim=simulator.ydim,\n",
    "    context_dim=simulator.xdim,\n",
    "    hidden_layer_dim=cfg.surrogate.hidden_layer_dim,\n",
    ")\n",
    "surrogate = surrogate.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.surrogate.self == \"load_surrogate\":\n",
    "    surrogate.load_state_dict(torch.load(cfg.surrogate.surrogate_path))\n",
    "elif cfg.surrogate.self == \"train_surrogate\":\n",
    "    surro_train_domain = box_domain.sample(cfg.surrogate.num_training_samples)\n",
    "    surro_train_push_forward = simulator.sample(surro_train_domain)\n",
    "\n",
    "    surro_optimizer = torch.optim.Adam(\n",
    "        surrogate.parameters(),\n",
    "        lr=cfg.surrogate.surrogate_lr,\n",
    "        weight_decay=cfg.surrogate.surrogate_weight_decay,\n",
    "    )\n",
    "\n",
    "    train_dataset, val_dataset = create_train_val_dataloaders(\n",
    "        surro_train_push_forward,\n",
    "        surro_train_domain,\n",
    "    )\n",
    "\n",
    "    train_loss, val_loss = fit_conditional_normalizing_flow(\n",
    "        network=surrogate,\n",
    "        optimizer=surro_optimizer,\n",
    "        training_dataset=train_dataset,\n",
    "        validation_dataset=val_dataset,\n",
    "        nb_epochs=cfg.surrogate.nb_epochs,\n",
    "        early_stopping_patience=cfg.surrogate.early_stopping_patience,\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        surrogate.state_dict(),\n",
    "        os.path.join(\n",
    "            cfg.base.base_path, cfg.base.folder, f\"{cfg.base.tag}_surrogate.pt\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plt.plot(train_loss, label=\"train loss\")\n",
    "    plt.plot(val_loss, label=\"validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    assert cfg.surrogate.self == \"no_surrogate\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from source distribution and push forward through surrogate simulator\n",
    "# Here, we evaluate on the source distribution!\n",
    "surrogate.eval()\n",
    "gt_source = simulator.sample_prior(cfg.source.num_obs)\n",
    "gt_source_two = simulator.sample_prior(cfg.source.num_eval_obs)\n",
    "with torch.no_grad():\n",
    "    gt_surrogate = surrogate.sample(cfg.source.num_obs, gt_source)\n",
    "    gt_surrogate_two = surrogate.sample(cfg.source.num_eval_obs, gt_source_two)\n",
    "    gt_simulator = simulator.sample(gt_source)\n",
    "    gt_simulator_two = simulator.sample(gt_source_two)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.surrogate.self == \"load_surrogate\" or cfg.surrogate.self == \"train_surrogate\":\n",
    "    print(\"Surrogate vs Simulator y-space C2ST AUC:\")\n",
    "    print(np.mean(c2st_scores(gt_simulator.cpu(), gt_surrogate.cpu())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sliced wassertein distance on groundtruth y:\")\n",
    "excepted_distance = sliced_wasserstein_distance(\n",
    "    gt_simulator[: cfg.source.num_eval_obs],\n",
    "    gt_simulator_two,\n",
    "    num_projections=4096,\n",
    "    device=device,\n",
    ").item()\n",
    "print(excepted_distance)\n",
    "print(np.log(excepted_distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source model\n",
    "if cfg.source_model.self == \"sampler\":\n",
    "    source = Sampler(\n",
    "        xdim=simulator.xdim,\n",
    "        input_noise_dim=simulator.xdim,\n",
    "        hidden_layer_dim=cfg.source_model.hidden_layer_dim,\n",
    "        num_hidden_layers=cfg.source_model.num_hidden_layers,\n",
    "        low=cfg.simulator.box_domain_lower,\n",
    "        high=cfg.simulator.box_domain_upper,\n",
    "    )\n",
    "elif cfg.source_model.self == \"real_nvp\":\n",
    "    source = RealNVPs(\n",
    "        data_dim=simulator.xdim,\n",
    "        context_dim=0,\n",
    "        hidden_layer_dim=cfg.source_model.hidden_layer_dim,\n",
    "        flow_length=cfg.source_model.flow_length,\n",
    "        low=cfg.simulator.box_domain_lower,\n",
    "        high=cfg.simulator.box_domain_upper,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "source = source.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train source model\n",
    "optimizer = torch.optim.Adam(\n",
    "    source.parameters(),\n",
    "    lr=cfg.source.learning_rate,\n",
    "    weight_decay=cfg.source.weight_decay,\n",
    ")\n",
    "\n",
    "# This is the scheduled values of lambda - first we linearly decay from lambda=1.0 (only entropy) until a minimum value of lambda. Then we stay at that value of lambda for more iterations.\n",
    "schedule = torch.cat(\n",
    "    [\n",
    "        torch.ones(cfg.source.pretraining_steps),\n",
    "        torch.linspace(\n",
    "            1.0,\n",
    "            cfg.source.fin_lambda,\n",
    "            cfg.source.linear_decay_steps,\n",
    "        ),\n",
    "        cfg.source.fin_lambda * torch.ones(cfg.source.lambda_steps),\n",
    "    ]\n",
    ")\n",
    "\n",
    "if cfg.source.self == \"wasserstein\":\n",
    "    train_source(\n",
    "        data=gt_simulator,\n",
    "        source_model=source,\n",
    "        simulator=simulator if cfg.surrogate.self == \"no_surrogate\" else surrogate,\n",
    "        optimizer=optimizer,\n",
    "        entro_dist=None,  # default uniform is used\n",
    "        kld_samples=cfg.source.num_kole_samples,\n",
    "        entro_lambda=schedule,\n",
    "        wasser_p=cfg.source.wasserstein_order,\n",
    "        wasser_np=cfg.source.wasserstein_slices,\n",
    "        use_log_sw=cfg.source.use_log_sw,\n",
    "        num_chunks=cfg.source.num_chunks,\n",
    "        epochs=cfg.source.pretraining_steps\n",
    "        + cfg.source.linear_decay_steps\n",
    "        + cfg.source.lambda_steps,\n",
    "        min_epochs_x_chus=cfg.source.pretraining_steps + cfg.source.linear_decay_steps,\n",
    "        early_stopping_patience=cfg.source.early_stopping_patience,\n",
    "        device=device,\n",
    "    )\n",
    "elif cfg.source.self == \"mll\":\n",
    "    assert cfg.surrogate.self != \"no_surrogate\"\n",
    "\n",
    "    train_lml_source(\n",
    "        observations=gt_simulator,\n",
    "        source_model=source,\n",
    "        likelihood_model=surrogate,\n",
    "        optimizer=optimizer,\n",
    "        lam=schedule,\n",
    "        entro_target=None,  # default uniform is used\n",
    "        batch_size=cfg.source.batch_size,\n",
    "        nb_mc_integration_steps=cfg.source.nb_mc_integration_steps,\n",
    "        num_kole_samples=cfg.source.num_kole_samples,\n",
    "        nb_epochs=cfg.source.nb_epochs,\n",
    "        validation_set_size=cfg.source.validation_set_size,\n",
    "        early_stopping_min_epochs=cfg.source.early_stopping_min_epochs,\n",
    "        early_stopping_patience=cfg.source.early_stopping_patience,\n",
    "        print_every=cfg.source.print_every,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state_dict(\n",
    "    source,\n",
    "    f\"{cfg.base.tag}_learned_source.pt\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained source model\n",
    "source.eval()\n",
    "surrogate.eval()\n",
    "with torch.no_grad():\n",
    "    estimated_source = source.sample(cfg.source.num_eval_obs)\n",
    "    surro_estimated_pf = surrogate.sample(cfg.source.num_eval_obs, estimated_source)\n",
    "    simu_estimated_pf = simulator.sample(estimated_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot true and learned sources\n",
    "fig_source = corner(\n",
    "    gt_source_two.cpu().numpy(),\n",
    "    color=\"black\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "corner(\n",
    "    estimated_source.cpu().numpy(),\n",
    "    fig=fig_source,\n",
    "    color=\"red\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "\n",
    "save_fig(\n",
    "    fig_source,\n",
    "    file_name=f\"{cfg.base.tag}_source_fig.pdf\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid plotting very large corner plots\n",
    "plot_ss = slice(None)\n",
    "if cfg.simulator.self == \"sir\":\n",
    "    plot_ss = slice(1, 50, 4)\n",
    "elif cfg.simulator.self == \"lotka_volterra\":\n",
    "    plot_ss = slice(10, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pairplots in observation space with surrogate\n",
    "fig_surro = corner(\n",
    "    gt_surrogate_two.cpu().numpy()[:, plot_ss],\n",
    "    color=\"black\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "corner(\n",
    "    surro_estimated_pf.cpu().numpy()[:, plot_ss],\n",
    "    fig=fig_surro,\n",
    "    color=\"red\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "\n",
    "save_fig(\n",
    "    fig_surro,\n",
    "    file_name=f\"{cfg.base.tag}_surrogate_fig.pdf\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pairplots in observation space with true simulator\n",
    "fig_simu = corner(\n",
    "    gt_simulator_two.cpu().numpy()[:, plot_ss],\n",
    "    color=\"black\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "corner(\n",
    "    simu_estimated_pf.cpu().numpy()[:, plot_ss],\n",
    "    fig=fig_simu,\n",
    "    color=\"red\",\n",
    "    bins=20,\n",
    "    hist_kwargs={\"density\": True},\n",
    "    plot_contours=False,\n",
    "    plot_density=False,\n",
    "    # plot_datapoints=False,\n",
    ")\n",
    "\n",
    "save_fig(\n",
    "    fig_simu,\n",
    "    file_name=f\"{cfg.base.tag}_simulator_fig.pdf\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier two sample tests\n",
    "c2st_ss = slice(None)\n",
    "if cfg.simulator.self == \"sir\":\n",
    "    c2st_ss = slice(1, 50)\n",
    "\n",
    "print(\"y c2st AUC on simulator:\")\n",
    "simu_c2st = np.mean(\n",
    "    c2st_scores(\n",
    "        simu_estimated_pf.cpu()[:, c2st_ss],\n",
    "        gt_simulator_two.cpu()[:, c2st_ss],\n",
    "    )\n",
    ")\n",
    "print(simu_c2st)\n",
    "\n",
    "print(\"y c2st AUC on surrogate:\")\n",
    "surro_c2st = np.mean(\n",
    "    c2st_scores(\n",
    "        surro_estimated_pf.cpu()[:, c2st_ss],\n",
    "        gt_surrogate.cpu()[:, c2st_ss],\n",
    "    )\n",
    ")\n",
    "print(surro_c2st)\n",
    "\n",
    "print(\"Source c2st AUC:\")\n",
    "source_c2st = np.mean(\n",
    "    c2st_scores(\n",
    "        estimated_source.cpu(),\n",
    "        gt_source_two.cpu(),\n",
    "    )\n",
    ")\n",
    "print(source_c2st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_numpy_csv(\n",
    "    np.array([simu_c2st]),\n",
    "    file_name=f\"{cfg.base.tag}_simu_c2st.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "save_numpy_csv(\n",
    "    np.array([surro_c2st]),\n",
    "    file_name=f\"{cfg.base.tag}_surro_c2st.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n",
    "save_numpy_csv(\n",
    "    np.array([source_c2st]),\n",
    "    file_name=f\"{cfg.base.tag}_source_c2st.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Estimate source entropies\")\n",
    "gt_source_kole = kozachenko_leonenko_estimator(gt_source_two, on_torus=False).item()\n",
    "estimated_source_kole = kozachenko_leonenko_estimator(\n",
    "    estimated_source, on_torus=False\n",
    ").item()\n",
    "\n",
    "print(\"Ground truth source entropy estimate:\")\n",
    "print(gt_source_kole)\n",
    "print(\"Estimated source entropy estimate:\")\n",
    "print(estimated_source_kole)\n",
    "\n",
    "save_numpy_csv(\n",
    "    np.array([gt_source_kole]),\n",
    "    file_name=f\"{cfg.base.tag}_gt_source_kole.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "save_numpy_csv(\n",
    "    np.array([estimated_source_kole]),\n",
    "    file_name=f\"{cfg.base.tag}_estimated_source_kole.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: For a better estimate, resample from ground truth here as well!\n",
    "num_repeat = 10\n",
    "surro_dists = np.zeros(num_repeat)\n",
    "simu_dists = np.zeros(num_repeat)\n",
    "for idx in range(10):\n",
    "    with torch.no_grad():\n",
    "        surro_est_pf_add = surrogate.sample(\n",
    "            cfg.source.num_eval_obs, source.sample(cfg.source.num_eval_obs)\n",
    "        )\n",
    "        simu_est_pf_add = simulator.sample(source.sample(cfg.source.num_eval_obs))\n",
    "    surro_dists[idx] = sliced_wasserstein_distance(\n",
    "        gt_simulator_two,\n",
    "        surro_est_pf_add,\n",
    "        num_projections=4096,\n",
    "        device=device,\n",
    "    )\n",
    "    simu_dists[idx] = sliced_wasserstein_distance(\n",
    "        gt_simulator_two,\n",
    "        simu_est_pf_add,\n",
    "        num_projections=4096,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "print(np.mean(surro_dists))\n",
    "print(np.std(surro_dists))\n",
    "\n",
    "print(np.mean(simu_dists))\n",
    "print(np.std(simu_dists))\n",
    "\n",
    "save_numpy_csv(\n",
    "    surro_dists,\n",
    "    file_name=f\"{cfg.base.tag}_surro_pf_swds.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "save_numpy_csv(\n",
    "    simu_dists,\n",
    "    file_name=f\"{cfg.base.tag}_simu_pf_swds.csv\",\n",
    "    folder=cfg.base.folder,\n",
    "    base_path=cfg.base.base_path,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for Lotka Volterra\n",
    "if cfg.simulator.self == \"lotka_volterra\":\n",
    "    gt_simulator_two_np = gt_simulator_two.cpu().numpy()\n",
    "    simu_estimated_pf_np = simu_estimated_pf.cpu().numpy()\n",
    "    plt.fill_between(\n",
    "        np.arange(50),\n",
    "        np.quantile(simu_estimated_pf_np[:, 50:], 0.25, axis=0),\n",
    "        np.quantile(simu_estimated_pf_np[:, 50:], 0.75, axis=0),\n",
    "        color=\"r\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        np.arange(50),\n",
    "        np.quantile(simu_estimated_pf_np[:, :50], 0.25, axis=0),\n",
    "        np.quantile(simu_estimated_pf_np[:, :50], 0.75, axis=0),\n",
    "        color=\"blue\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    plt.plot(np.mean(simu_estimated_pf_np[:, 50:], axis=0), c=\"r\")\n",
    "    plt.plot(np.mean(simu_estimated_pf_np[:, :50], axis=0), c=\"b\")\n",
    "    plt.show()\n",
    "    plt.fill_between(\n",
    "        np.arange(50),\n",
    "        np.quantile(gt_simulator_two_np[:, 50:], 0.25, axis=0),\n",
    "        np.quantile(gt_simulator_two_np[:, 50:], 0.75, axis=0),\n",
    "        color=\"r\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        np.arange(50),\n",
    "        np.quantile(gt_simulator_two_np[:, :50], 0.25, axis=0),\n",
    "        np.quantile(gt_simulator_two_np[:, :50], 0.75, axis=0),\n",
    "        color=\"blue\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    plt.plot(np.mean(gt_simulator_two_np[:, 50:], axis=0), c=\"r\")\n",
    "    plt.plot(np.mean(gt_simulator_two_np[:, :50], axis=0), c=\"b\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.simulator.self == \"sir\":\n",
    "    num_samps = 100\n",
    "    rand_ids = np.random.choice(10000, size=num_samps, replace=False)\n",
    "    gt_simulator_two_np = gt_simulator_two.cpu().numpy()\n",
    "    simu_estimated_pf_np = simu_estimated_pf.cpu().numpy()\n",
    "    # plot samples interleaved\n",
    "    for i in rand_ids:\n",
    "        plt.plot(gt_simulator_two_np[i], c=\"black\", alpha=0.1)\n",
    "        plt.plot(simu_estimated_pf_np[i], c=\"C3\", alpha=0.1)\n",
    "    for i in range(1, 10):\n",
    "        plt.plot(\n",
    "            np.quantile(gt_simulator_two_np, 0.1 * i, axis=0),\n",
    "            c=\"black\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            np.quantile(simu_estimated_pf_np, 0.1 * i, axis=0),\n",
    "            c=\"C3\",\n",
    "        )\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
